{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb1523-325b-40c6-940b-79b3609d38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xml.etree import ElementTree as ET\n",
    "from statistics import mean\n",
    "from tqdm import tqdm\n",
    "\n",
    "ROOT_DIR = \".\"\n",
    "L_FOOT_ID, R_FOOT_ID = 21, 17\n",
    "\n",
    "def extract_foot_contacts_simple(mvnx_path):\n",
    "    try:\n",
    "        tree = ET.parse(mvnx_path)\n",
    "        root = tree.getroot()\n",
    "        rows = []\n",
    "        for frame in root.findall('.//{http://www.xsens.com/mvn/mvnx}frame'):\n",
    "            fc = frame.find('.//{http://www.xsens.com/mvn/mvnx}footContacts')\n",
    "            if fc is not None and fc.text:\n",
    "                rows.append(list(map(int, fc.text.strip().split())))\n",
    "        return np.array(rows) if rows else np.empty((0, 4), dtype=int)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Contact‚Äëparse error in {mvnx_path}: {e}\")\n",
    "        return np.empty((0, 4), dtype=int)\n",
    "\n",
    "def extract_segment_positions_and_time(mvnx_path):\n",
    "    try:\n",
    "        tree = ET.parse(mvnx_path)\n",
    "        root = tree.getroot()\n",
    "        ns_uri = root.tag.split('}')[0].strip('{')\n",
    "        ns = {'ns': ns_uri}\n",
    "        pos_rows, t_rows = [], []\n",
    "        for fr in root.findall('.//ns:frame', ns):\n",
    "            pos_el = fr.find('ns:position', ns)\n",
    "            t_ms = fr.get('time')\n",
    "            if pos_el is not None and pos_el.text and t_ms:\n",
    "                pos_rows.append(list(map(float, pos_el.text.split())))\n",
    "                t_rows.append(float(t_ms) / 1000.0)\n",
    "        return (\n",
    "            np.array(pos_rows) if pos_rows else np.empty((0, 69)),\n",
    "            np.array(t_rows) if t_rows else np.empty(0)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Position/time parse error in {mvnx_path}: {e}\")\n",
    "        return np.empty((0, 69)), np.empty(0)\n",
    "\n",
    "def detect_heel_strikes(contacts):\n",
    "    # Returns all heel strikes for both feet, as (index, foot) tuples\n",
    "    events = []\n",
    "    for foot_col, foot_name in [(contacts[:,0], \"L\"), (contacts[:,2], \"R\")]:\n",
    "        if foot_col.size < 2:\n",
    "            continue\n",
    "        strikes = np.where((foot_col[1:] == 1) & (foot_col[:-1] == 0))[0] + 1\n",
    "        events.extend([(idx, foot_name) for idx in strikes])\n",
    "    return sorted(events, key=lambda x: x[0])\n",
    "\n",
    "\n",
    "def detect_toe_offs(contacts):\n",
    "    events = []\n",
    "    for col_idx, foot in [(1, \"L\"), (3, \"R\")]:  # Toe off = 1 ‚Üí 0\n",
    "        foot_col = contacts[:, col_idx]\n",
    "        if foot_col.size < 2:\n",
    "            continue\n",
    "        toe_offs = np.where((foot_col[1:] == 0) & (foot_col[:-1] == 1))[0] + 1\n",
    "        events.extend([(idx, foot) for idx in toe_offs])\n",
    "    return sorted(events, key=lambda x: x[0])\n",
    "\n",
    "\n",
    "\n",
    "def robust_mean_width(widths, minval=0.03, maxval=0.3):\n",
    "    filtered = [w for w in widths if minval < w < maxval]\n",
    "    return np.mean(filtered) if len(filtered) >= 2 else None\n",
    "\n",
    "def compute_support_phases_from_strides(contacts, heel_strikes):\n",
    "    if len(heel_strikes) < 4:\n",
    "        return None, None, None\n",
    "\n",
    "    ds_vals, ssL_vals, ssR_vals = [], [], []\n",
    "\n",
    "    for i in range(len(heel_strikes) - 2):\n",
    "        idx1, foot1 = heel_strikes[i]\n",
    "        idx2, foot2 = heel_strikes[i + 2]\n",
    "\n",
    "        if foot1 != foot2:\n",
    "            continue  # skip if not a full stride (same foot to same foot)\n",
    "\n",
    "        window = contacts[idx1:idx2]\n",
    "        if window.shape[0] < 2:\n",
    "            continue\n",
    "\n",
    "        L = window[:, 0]\n",
    "        R = window[:, 2]\n",
    "        total = len(window)\n",
    "\n",
    "        ds = np.sum((L == 1) & (R == 1))\n",
    "        ssL = np.sum((L == 1) & (R == 0))\n",
    "        ssR = np.sum((L == 0) & (R == 1))\n",
    "\n",
    "        ds_vals.append(100 * ds / total)\n",
    "        ssL_vals.append(100 * ssL / total)\n",
    "        ssR_vals.append(100 * ssR / total)\n",
    "\n",
    "    return (\n",
    "        round(np.mean(ds_vals), 2) if ds_vals else None,\n",
    "        round(np.mean(ssL_vals), 2) if ssL_vals else None,\n",
    "        round(np.mean(ssR_vals), 2) if ssR_vals else None\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def get_progression_unit_vector(pos, L_idx, R_idx):\n",
    "    feet_traj_L = pos[:, L_idx:L_idx+2]\n",
    "    feet_traj_R = pos[:, R_idx:R_idx+2]\n",
    "    feet_traj = (feet_traj_L + feet_traj_R) / 2\n",
    "    delta = feet_traj[-1] - feet_traj[0]\n",
    "    norm = np.linalg.norm(delta)\n",
    "    if norm == 0:\n",
    "        return np.array([1, 0])\n",
    "    return delta / norm\n",
    "\n",
    "def project_point_onto_vector(p, origin, vec):\n",
    "    vec = vec / np.linalg.norm(vec)\n",
    "    rel = p[:2] - origin[:2]\n",
    "    forward = np.dot(rel, vec)\n",
    "    ortho_vec = np.array([-vec[1], vec[0]])\n",
    "    lateral = np.dot(rel, ortho_vec)\n",
    "    return forward, lateral\n",
    "\n",
    "def compute_spatial_params_progression(events, pos):\n",
    "    l_idx = L_FOOT_ID * 3\n",
    "    r_idx = R_FOOT_ID * 3\n",
    "    prog_vec = get_progression_unit_vector(pos, l_idx, r_idx)\n",
    "    origin = (pos[0, l_idx:l_idx+2] + pos[0, r_idx:r_idx+2]) / 2\n",
    "    fwd_lat_points = []\n",
    "    for idx, foot in events:\n",
    "        if foot == 'L':\n",
    "            fwd_lat_points.append(project_point_onto_vector(pos[idx, l_idx:l_idx+2], origin, prog_vec))\n",
    "        else:\n",
    "            fwd_lat_points.append(project_point_onto_vector(pos[idx, r_idx:r_idx+2], origin, prog_vec))\n",
    "    # Step length = distance between consecutive events\n",
    "    step_lengths = [abs(fwd_lat_points[i+1][0] - fwd_lat_points[i][0]) for i in range(len(fwd_lat_points)-1)]\n",
    "    # Stride length = every second event (one full gait cycle)\n",
    "    stride_lengths = []\n",
    "    for i in range(0, len(fwd_lat_points)-2, 2):\n",
    "        if i+2 < len(fwd_lat_points):\n",
    "            stride_lengths.append(abs(fwd_lat_points[i+2][0] - fwd_lat_points[i][0]))\n",
    "    # Step width = orthogonal (lateral) distance between consecutive events\n",
    "    step_widths = [abs(fwd_lat_points[i+1][1] - fwd_lat_points[i][1]) for i in range(len(fwd_lat_points)-1)]\n",
    "    return step_lengths, stride_lengths, step_widths\n",
    "\n",
    "def analyze_file(path):\n",
    "    print(f\"üìÇ  Processing {path}\")\n",
    "    contacts = extract_foot_contacts_simple(path)\n",
    "    pos, times = extract_segment_positions_and_time(path)\n",
    "    if contacts.shape[0] < 2 or times.size < 2:\n",
    "        print(\"   ‚ö†Ô∏è  too few frames ‚Äì skipped\")\n",
    "        return None\n",
    "    if abs(contacts.shape[0] - times.size) > 10:\n",
    "        m = min(contacts.shape[0], times.size)\n",
    "        contacts, pos, times = contacts[:m], pos[:m], times[:m]\n",
    "\n",
    "    # All heel strikes as (index, foot), sorted by index\n",
    "    events = detect_heel_strikes(contacts)\n",
    "    if len(events) < 2:\n",
    "        print(\"   ‚ö†Ô∏è  no heel strikes ‚Äì skipped\")\n",
    "        return None\n",
    "\n",
    "    # Store counts before trimming\n",
    "    n_steps_total = len(events) - 1\n",
    "    n_strides_total = max(0, (len(events) - 1) // 2)\n",
    "\n",
    "    # Remove first and last 2 for stability\n",
    "    trim = 2\n",
    "    events_trim = events[trim:-trim] if len(events) > 2*trim else events\n",
    "    n_steps_trim = len(events_trim) - 1\n",
    "    n_strides_trim = max(0, (len(events_trim) - 1) // 2)\n",
    "\n",
    "    # Extract indices and times for trimmed events\n",
    "    trimmed_indices = [idx for idx, _ in events_trim]\n",
    "    trimmed_times = [times[idx] for idx in trimmed_indices]\n",
    "\n",
    "    # --- Temporal metrics (step/stride times) ---\n",
    "    step_times = [trimmed_times[i+1] - trimmed_times[i] for i in range(len(trimmed_times)-1)]\n",
    "    stride_times = []\n",
    "    for i in range(0, len(trimmed_times)-2, 2):\n",
    "        if i+2 < len(trimmed_times):\n",
    "            stride_times.append(trimmed_times[i+2] - trimmed_times[i])\n",
    "\n",
    "    mean_step_time = mean(step_times) if step_times else None\n",
    "    mean_stride_time = mean(stride_times) if stride_times else None\n",
    "\n",
    "    # --- Spatial metrics ---\n",
    "    step_lengths, stride_lengths, step_widths = compute_spatial_params_progression(events_trim, pos)\n",
    "    mean_step_length = mean(step_lengths) if step_lengths else None\n",
    "    mean_stride_length = mean(stride_lengths) if stride_lengths else None\n",
    "    mean_step_width = robust_mean_width(step_widths)\n",
    "\n",
    "    gait_speed = (mean_stride_length / mean_stride_time) if (mean_stride_length and mean_stride_time) else None\n",
    "    ds_pct, ssL_pct, ssR_pct = compute_support_phases_from_strides(contacts, events)\n",
    "    trial_time = trimmed_times[-1] - trimmed_times[0] if len(trimmed_times) > 1 else None\n",
    "    cadence = round(n_steps_trim / (trial_time / 60), 2) if trial_time and n_steps_trim > 0 else None\n",
    "\n",
    "    results = {\n",
    "        \"n_steps_total\": n_steps_total,\n",
    "        \"n_strides_total\": n_strides_total,\n",
    "        \"n_steps_trimmed\": n_steps_trim,\n",
    "        \"n_strides_trimmed\": n_strides_trim,\n",
    "        \n",
    "        \"gait_speed_mps\": round(gait_speed, 3) if gait_speed else None,\n",
    "        \"cadence_spm\": cadence,\n",
    "\n",
    "        \"step_time_mean_s\": round(mean_step_time, 3) if mean_step_time else None,\n",
    "        \"step_time_sd_s\": round(np.std(step_times), 3) if step_times else None,\n",
    "\n",
    "        \"stride_time_mean_s\": round(mean_stride_time, 3) if mean_stride_time else None,\n",
    "        \"stride_time_sd_s\": round(np.std(stride_times), 3) if stride_times else None,\n",
    "\n",
    "        \"step_length_mean_m\": round(mean(step_lengths), 3) if step_lengths else None,\n",
    "        \"step_length_sd_m\": round(np.std(step_lengths), 3) if step_lengths else None,\n",
    "\n",
    "        \"stride_length_mean_m\": round(mean(stride_lengths), 3) if stride_lengths else None,\n",
    "        \"stride_length_sd_m\": round(np.std(stride_lengths), 3) if stride_lengths else None,\n",
    "\n",
    "        \"step_width_mean_m_orth\": round(mean_step_width, 3) if mean_step_width else None,\n",
    "        \"step_width_sd_m_orth\": round(np.std(step_widths), 3) if step_widths else None,\n",
    "\n",
    "        \"double_support_pct\": ds_pct,\n",
    "        \"single_support_L_pct\": ssL_pct,\n",
    "        \"single_support_R_pct\": ssR_pct,\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    all_rows = []\n",
    "    for grp in tqdm(os.listdir(ROOT_DIR), desc=\"Groups\"):\n",
    "        p_grp = os.path.join(ROOT_DIR, grp)\n",
    "        if not os.path.isdir(p_grp):\n",
    "            continue\n",
    "        for subj in tqdm(os.listdir(p_grp), desc=f\"{grp} Participants\", leave=False):\n",
    "            p_subj = os.path.join(p_grp, subj)\n",
    "            if not os.path.isdir(p_subj):\n",
    "                continue\n",
    "            gait_dir = next(\n",
    "                (os.path.join(p_subj, d) for d in os.listdir(p_subj)\n",
    "                 if d.lower() == \"gait\"),\n",
    "                None\n",
    "            )\n",
    "            if not gait_dir:\n",
    "                continue\n",
    "            for pace in os.listdir(gait_dir):\n",
    "                p_pace = os.path.join(gait_dir, pace)\n",
    "                if not os.path.isdir(p_pace):\n",
    "                    continue\n",
    "                for fx in os.listdir(p_pace):\n",
    "                    if not fx.lower().endswith(\".mvnx\"):\n",
    "                        continue\n",
    "                    full = os.path.join(p_pace, fx)\n",
    "                    res = analyze_file(full)\n",
    "                    if res is None:\n",
    "                        continue\n",
    "                    meta = {\n",
    "                        \"group\": grp,\n",
    "                        \"participant\": subj,\n",
    "                        \"pace_condition\": pace.lower(),\n",
    "                        \"source_file\": fx\n",
    "                    }\n",
    "                    all_rows.append({**meta, **res})\n",
    "    if not all_rows:\n",
    "        print(\"‚ùå  No valid MVNX files processed.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    out_fn = \"gait_analysis_global.csv\"\n",
    "    df.to_csv(out_fn, index=False, float_format=\"%.4f\")\n",
    "    print(f\"\\n‚úÖ  Exported {len(df)} rows ‚Üí {out_fn}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa68db79-44f0-4902-81c0-2c1b6f551504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
